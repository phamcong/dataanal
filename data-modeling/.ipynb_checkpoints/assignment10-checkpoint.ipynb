{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.io.wavfile as wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good Luck!\n",
    "\n",
    "#\n",
    "# INFO:\n",
    "# Samples = Observations. Each audio file will is a single sample\n",
    "#           in our dataset.\n",
    "#\n",
    "# Audio Samples = https://en.wikipedia.org/wiki/Sampling_(signal_processing)\n",
    "# Each .wav file is actually just a bunch of numeric samples, \"sampled\"\n",
    "# from the analog signal. Sampling is a type of discretization. When we\n",
    "# mention 'samples', we mean observations. When we mention 'audio samples',\n",
    "# we mean the actually \"features\" of the audio file.\n",
    "#\n",
    "#\n",
    "# The goal of this lab is to use multi-target, linear regression to generate\n",
    "# by extrapolation, the missing portion of the test audio file.\n",
    "#\n",
    "# Each one audio_sample features will be the output of an equation,\n",
    "# which is a function of the provided portion of the audio_samples:\n",
    "#\n",
    "#    missing_samples = f(provided_samples)\n",
    "#\n",
    "# You can experiment with how much of the audio you want to chop off\n",
    "# and have the computer generate using the Provided_Portion parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Play with this. This is how much of the audio file will\n",
    "# be provided, in percent. The remaining percent of the file will\n",
    "# be generated via linear extrapolation.\n",
    "Provided_Portion = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INFO: You have to download the dataset (audio files) from the website:\n",
    "# https://github.com/Jakobovski/free-spoken-digit-dataset\n",
    "#\n",
    "# TODO: Create a regular ol' Python List called 'zero'\n",
    "# Loop through the dataset and load up all 50 of the 0_jackson*.wav files\n",
    "# For each audio file, simply append the audio data (not the sample_rate,\n",
    "# just the data!) to your Python list 'zero':\n",
    "#\n",
    "zero = []\n",
    "for i in range(0,50):\n",
    "    sample_rate, audio_data = wavfile.read('Datasets/recordings/0_jackson_' + str(i) + '.wav')\n",
    "    zero.append(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# TODO: Just for a second, convert zero into a DataFrame. When you do\n",
    "# so, set the dtype to np.int16, since the input audio files are 16\n",
    "# bits per sample. If you don't know how to do this, read up on the docs\n",
    "# here:\n",
    "# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "#\n",
    "# Since these audio clips are unfortunately not length-normalized,\n",
    "# we're going to have to just hard chop them to all be the same length.\n",
    "# Since Pandas would have inserted NANs at any spot to make zero a \n",
    "# perfectly rectangular [n_observed_samples, n_audio_samples] array,\n",
    "# do a dropna on the Y axis here. Then, convert one back into an\n",
    "# NDArray using .values\n",
    "#\n",
    "df = pd.DataFrame(data=zero, dtype='int16')\n",
    "df.dropna(axis=1, inplace=True)\n",
    "zero = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: It's important to know how (many audio_samples samples) long the\n",
    "# data is now. 'zero' is currently shaped [n_samples, n_audio_samples],\n",
    "# so get the n_audio_samples count and store it in a variable called\n",
    "# n_audio_samples\n",
    "#\n",
    "n_audio_samples = zero.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Create your linear regression model here and store it in a\n",
    "# variable called 'model'. Don't actually train or do anything else\n",
    "# with it yet:\n",
    "#\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# INFO: There are 50 takes of each clip. You want to pull out just one\n",
    "# of them, randomly, and that one will NOT be used in the training of\n",
    "# your model. In other words, the one file we'll be testing / scoring\n",
    "# on will be an unseen sample, independent to the rest of your\n",
    "# training set:\n",
    "from sklearn.utils.validation import check_random_state\n",
    "rng   = check_random_state(7)  # Leave this alone until you've submitted your lab\n",
    "random_idx = rng.randint(zero.shape[0])\n",
    "test  = zero[random_idx]\n",
    "train = np.delete(zero, [random_idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (49, 4087)\n",
      "Test shape:  (4087,)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# TODO: Print out the shape of train, and the shape of test\n",
    "# train will be shaped: [n_samples, n_audio_samples], where\n",
    "# n_audio_samples are the 'features' of the audio file\n",
    "# test will be shaped [n_audio_features], since it is a single\n",
    "# sample (audio file, e.g. observation).\n",
    "#\n",
    "print('Train shape: ', train.shape)\n",
    "print('Test shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# INFO: The test data will have two parts, X_test and y_test. X_test is\n",
    "# going to be the first portion of the test audio file, which we will\n",
    "# be providing the computer as input. y_test, the \"label\" if you will,\n",
    "# is going to be the remaining portion of the audio file. Like such, \n",
    "# the computer will use linear regression to derive the missing\n",
    "# portion of the sound file based off of the training data its received!\n",
    "\n",
    "#\n",
    "# Save the original 'test' clip, the one you're about to delete\n",
    "# half of, so that you can compare it to the 'patched' clip once \n",
    "# you've generated it. HINT: you should have got the sample_rate\n",
    "# when you were loading up the .wav files:\n",
    "wavfile.write('Datasets/recordings/Original Test Clip.wav', sample_rate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Prepare the TEST date by creating a slice called X_test. It\n",
    "# should have Provided_Portion * n_audio_samples audio sample features,\n",
    "# taken from your test audio file, currently stored in the variable\n",
    "# 'test'. In other words, grab the FIRST Provided_Portion *\n",
    "# n_audio_samples audio features from test and store it in X_test.\n",
    "#\n",
    "X_test = test[:int(Provided_Portion*n_audio_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: If the first Provided_Portion * n_audio_samples features were\n",
    "# stored in X_test, then we need to also grab the *remaining* audio\n",
    "# features and store it in y_test. With the remaining features stored\n",
    "# in there, we will be able to R^2 \"score\" how well our algorithm did\n",
    "# in completing the sound file.\n",
    "#\n",
    "y_test = test[int(Provided_Portion*n_audio_samples):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# TODO: Duplicate the same process for X_train, y_train. The only\n",
    "# differences being: 1) Your will be getting your audio data from\n",
    "# 'train' instead of from 'test', 2) Remember the shape of train that\n",
    "# you printed out earlier? You want to do this slicing but for ALL\n",
    "# samples (observations). For each observation, you want to slice\n",
    "# the first Provided_Portion * n_audio_samples audio features into\n",
    "# X_train, and the remaining go into y_test. All of this should be\n",
    "# accomplishable using regular indexing in two lines of code.\n",
    "#\n",
    "X_train = train[:,:int(Provided_Portion*n_audio_samples)]\n",
    "y_train = train[:,int(Provided_Portion*n_audio_samples):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# TODO: SciKit-Learn gets mad if you don't supply your training\n",
    "# data in the form of a 2D arrays: [n_samples, n_features].\n",
    "#\n",
    "# So if you only have one SAMPLE, such as is our case with X_test, \n",
    "# and y_test, then by calling .reshape(1, -1), you can turn\n",
    "# [n_features] into [1, n_features].\n",
    "#\n",
    "# On the other hand, if you only have one FEATURE, which currently\n",
    "# doesn't apply, you can call .reshape(-1, 1) on your data to turn\n",
    "# [n_samples] into [n_samples, 1]:\n",
    "#\n",
    "X_test = X_test.reshape(1, -1)\n",
    "y_test = y_test.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# TODO: Fit your model using your training data and label:\n",
    "#\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Use your model to predict the 'label' of X_test. Store the\n",
    "# resulting prediction in a variable called y_test_prediction\n",
    "#\n",
    "y_test_prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INFO: SciKit-Learn will use float64 to generate your predictions\n",
    "# so let's take those values back to int16:\n",
    "y_test_prediction = y_test_prediction.astype(dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation R^2 Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# TODO: Score how well your prediction would do for some good laughs,\n",
    "# by passing in your test data and test label (y_test).\n",
    "#\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Extrapolation R^2 Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# First, take the first Provided_Portion portion of the test clip, the\n",
    "# part you fed into your linear regression model. Then, stitch that\n",
    "# together with the abomination the predictor model generated for you,\n",
    "# and then save the completed audio clip:\n",
    "completed_clip = np.hstack((X_test, y_test_prediction))\n",
    "wavfile.write('Datasets/recordings/Extrapolated Clip.wav', sample_rate, completed_clip[0])\n",
    "\n",
    "#\n",
    "# INFO: Congrats on making it to the end of this crazy lab =) !\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
