{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1\n",
    "#### Lab Assignment 1\n",
    "Pick any game you know a decent amount about. It might be American football, soccer, ping-pong, rock-paper-scissors, Yoruba Ayo, League of Legends, Dungeons and Dragons, your job (if it's fun)â€”anything! As long as you are intimately familiar with it.\n",
    "\n",
    "Open up the /DAT210x/Module2/**assignment1.xls** file located the course repo. If you don't have Excel, the document looks like this:\n",
    "\n",
    "![lab-data-features](pic/lab-data-features.png)\n",
    "\n",
    "Notice how the **Type** column can only be *Numeric* or *Textual*, and the **Class** column can only be *Continuous*, *Ordinal*, or *Nominal*.\n",
    "\n",
    "Assuming you wanted to create a dataset that would hold various statistics about players playing the game you choose, come up with at least **seven** features of various type and class.\n",
    "\n",
    "#### Lab Question\n",
    "1. Have you completed the above assignment?\n",
    "  * [ ] No\n",
    "  * [ ] Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2\n",
    "#### Lab Assignment 2\n",
    "\n",
    "This time, you're going to attempt to load your first csv dataset! Open up the starter code located in Module2/assignment2.py. Read through it and follow the directions to:\n",
    "\n",
    "1. Load up Module2/Datasets/**tutorial.csv**\n",
    "2. Print the entire dataframe, using \n",
    "```python\n",
    "print df\n",
    "```\n",
    "3. Use the `.describe()` method on the dataset\n",
    "4. Slice the dataset using ```python [2:4, 'col3']```\n",
    "\n",
    "*Note: If Pandas complains about not being able to find the tutorial file, just use the full system path to it rather than a relative path. All paths mentioned in this course are in reference to the Module directory produced by unzipping the course material file*.\n",
    "\n",
    "##### Lab Questions 1\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Please enter a numeric value (e.g. 0, 1, 10.5, etc) which correctly answers the question(s) below:\n",
    "\n",
    "---\n",
    "\n",
    "When you print the results of calling **.describe()** on your dataframe, what is the value displayed in the bottom right corner (col3 max)?\n",
    "\n",
    ".......\n",
    "\n",
    "---\n",
    "\n",
    "##### Lab Questions 2\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Which of the many indexing methods did you use to get [2:4,'col3'] working?\n",
    "+ d.loc\n",
    "+ d.iloc\n",
    "+ d.col3\n",
    "+ d[]\n",
    "\n",
    "----\n",
    "##### Lab Questions 3\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Please enter a numeric value (e.g. 0, 1, 10.5, etc) which correctly answers the question(s) below:\n",
    "\n",
    "----\n",
    "How many values are returned when you print the results of the [2:4,'col3'] indexing operation?\n",
    "........"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignement 3\n",
    "#### Lab Assignment 3\n",
    "\n",
    "MIT's Karl Ulrich donated a dataset titled [Servo Data Set](https://archive.ics.uci.edu/ml/datasets/Servo) to the UCI Machine Learning Repository in the 1980's. The dataset has been described as \"an interesting collection of data that covers an extremely non-linear phenomenon - predicting the rise time of a servomechanism in terms of two (continuous) gain settings and two (discrete) choices of mechanical linkages.\"\n",
    "\n",
    "As noted on the dataset website above, the column names are defined in order as:\n",
    "```python\n",
    "['motor', 'screw', 'pgain', 'vgain', 'class']\n",
    "```\n",
    "Your mission, should you choose to accept, is to figure out a few stats about this dataset, which has been conveniently copied to your Module2/Datasets/**servo.data**. You can get started by opening up the assignment starter code, saved to Module2/**assignment3.py**.\n",
    "\n",
    "*Note: Before submitting, double check your work. Peek at the first few entries of your dataset, by opening up servo.data with a text editor. After that, use the appropriate command to look at the first few entries of your dataframe; do they match? If it's not a precise match, there might be a few useful parameters in the [read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) api documentation that will fix your issue!*\n",
    "\n",
    "---\n",
    "#### Lab Questions\n",
    "3 points possible (graded)\n",
    "\n",
    "Please enter a numeric value (e.g. 0, 1, 10.5, etc) which correctly answers the question(s) below:\n",
    "\n",
    "---\n",
    "How many samples in this dataset have a **vgain** feature value equal to 5?\n",
    "\n",
    "......\n",
    "\n",
    "How many samples in this dataset contain the value **E** for both motor and screw features?\n",
    "\n",
    "......\n",
    "\n",
    "What is the **mean vgain** value of those samples that have a **pgain** feature value equal to 4?\n",
    "\n",
    "......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4\n",
    "#### Lab Assignment 4\n",
    "\n",
    "Navigate over to ESPN's website for [NHL Historic Player Points Statistics](http://www.espn.com/nhl/statistics/player/_/stat/points/sort/points/year/2015/seasontype/2), for the years 2014-2015. This *page* has a table on it with a few stats we're interested in obtaining. But it's a bit messy! Clean it up for us, using the appropriate commands to:\n",
    "\n",
    "1. Load up the table on this page into a Pandas dataframe\n",
    "2. Rename the columns so that they match the column definitions on the website\n",
    "3. Get rid of any erroneous rows that has at least 4 NANs in them\n",
    "4. Get rid of the **RK** column\n",
    "5. Ensure there are no nan \"holes\" in your index\n",
    "6. Check the dtypes of all columns, and ensure those that *should* be numeric are numeric\n",
    "\n",
    "---\n",
    "#### Lab Questions\n",
    "3 points possible (graded)\n",
    "\n",
    "Please enter a numeric value (e.g. 0, 1, 10.5, etc) which correctly answers the question(s) below:\n",
    "\n",
    "---\n",
    "After completing the 6 steps above, how many rows remain in this dataset? (Not to be confused with the index!)\n",
    "\n",
    "......\n",
    "\n",
    "How many unique PCT values exist in the table?\n",
    "\n",
    "......\n",
    "\n",
    "What is the value you get by adding the GP values at indices 15 and 16 of this table?\n",
    "\n",
    "......\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Assignment 5\n",
    "#### Lab Assignment 5\n",
    "\n",
    "Barry Becker extracted a reasonably clean subset of the 1994, [U.S. Census database](https://archive.ics.uci.edu/ml/datasets/Census+Income), with a goal of running predictions to determine whether a person makes over 50K a year. The dataset is hosted on the University of California, Irvine's Machine Learning Repository and includes features such as the person's age, occupation, and hours worked per week, etc.\n",
    "\n",
    "As clean as the data is, it still isn't quite ready for analysis by SciKit-Learn! Using what you've learned in this chapter, clean up the various columns by encode them *properly* using the best practices so that they're ready to be examined. We've included a modifies *subset* of the dataset at Module2/Datasets/**census.data** and also have some started code to get you going located at Module2/**assignment5.py**.\n",
    "\n",
    "1. Load up the dataset and set header label names to:\n",
    "```python\n",
    "['education', 'age', 'capital-gain', 'race', 'capital-loss', 'hours-per-week', 'sex', 'classification']\n",
    "```\n",
    "Ensure you use the *right* command to do this, as there is more than one command! To verify you used the correct one, open the dataset in a text editor like SublimeText or Notepad, and double check your df.head() to ensure the first values match up.\n",
    "2. Make sure any value that needs to be replaced with a `NAN` is set as such. There are at least three ways to do this. One is *much* easier than the other two.\n",
    "3. Look through the dataset and ensure all of your columns have appropriate data types. *Numeric* columns should be `float64` or `int64`, and *textual* columns should be `object`.\n",
    "4. Properly encode any ordinal features using the method discussed in the chapter.\n",
    "5. Properly encode any nominal features by exploding them out into new, separate, boolean features.\n",
    "\n",
    "---\n",
    "#### Lab Question 1\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Please enter a numeric value (e.g. 0, 1, 2, 3, etc) which correctly answers the question(s) below:\n",
    "\n",
    "---\n",
    "Before you made any changes to the downloaded dataset, how many of the columns were ordinal?\n",
    "\n",
    "......\n",
    "\n",
    "---\n",
    "#### Lab Question 2\n",
    "\n",
    "1 point possible (graded)\n",
    "\n",
    "Please enter a numeric value (e.g. 0, 1, 2, 3, etc) which correctly answers the question(s) below:\n",
    "\n",
    "---\n",
    "Before you made any changes to the downloaded dataset, how many of the columns were nominal?\n",
    "\n",
    "......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
